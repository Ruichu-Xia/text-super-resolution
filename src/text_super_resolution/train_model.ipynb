{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_utils.dataset import LocalImageDataset, get_split_indices\n",
    "from model.ResNetSR import ResNetSR\n",
    "from model.utils import get_device, train_model_single_epoch, validate_model_single_epoch, save_checkpoint, save_samples, CombinedLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/test_indices.json\", \"r\") as f:\n",
    "    test_indices = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"data/resolution_128\"\n",
    "TARGET_DIR = \"data/resolution_256\"\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "GRAD_CLIP = 1\n",
    "EDGE_WEIGHT = 0.3\n",
    "PSNR_WEIGHT = 0.3\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_psnr\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_psnr\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len([f for f in os.listdir(INPUT_DIR) if f.endswith(('.jpg', '.png', '.jpeg', '.webp'))])\n",
    "train_indices, val_indices = get_split_indices(num_images, test_indices)\n",
    "\n",
    "train_loader = DataLoader(LocalImageDataset(INPUT_DIR, TARGET_DIR, train_indices), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(LocalImageDataset(INPUT_DIR, TARGET_DIR, val_indices), batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(LocalImageDataset(INPUT_DIR, TARGET_DIR, test_indices), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "save_ckpt = 2\n",
    "checkpoint_dir = \"ckpt\"\n",
    "\n",
    "n_samples = 5\n",
    "samples_to_visualize = DataLoader(LocalImageDataset(INPUT_DIR, TARGET_DIR, test_indices), batch_size=n_samples, shuffle=False)\n",
    "\n",
    "sample_dir = \"samples\"\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "model = ResNetSR(upscale_factor=2, num_res_blocks=2, num_channels=1, num_features=32)\n",
    "model = model.to(device)\n",
    "mae_loss = nn.L1Loss()\n",
    "criterion = CombinedLoss(mae_loss, EDGE_WEIGHT)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1, NUM_EPOCHS + 1):\n",
    "#     train_loss, train_psnr = train_model_single_epoch(model, train_loader, criterion, optimizer, device, scaler=None, grad_clip=GRAD_CLIP)\n",
    "#     val_loss, val_psnr = validate_model_single_epoch(model, val_loader, criterion, device)\n",
    "#     current_lr = scheduler.get_last_lr()[0]\n",
    "#     print(f\"[Epoch {epoch}/{NUM_EPOCHS}]\",\n",
    "#             f\"Train Loss: {train_loss:.4f}, PSNR: {train_psnr:.2f} | \"\n",
    "#             f\"Val Loss: {val_loss:.4f}, PSNR: {val_psnr:.2f} | \"\n",
    "#             f\"lr: {round(current_lr, 5)}\")\n",
    "\n",
    "#     if epoch % save_ckpt == 0:\n",
    "#         save_checkpoint(epoch+1, model, optimizer, history, checkpoint_dir)\n",
    "\n",
    "#         save_samples(epoch+1, model, val_loader, device, sample_dir, samples_to_visualize)\n",
    "\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         save_checkpoint(0, model, optimizer, history, checkpoint_dir)\n",
    "\n",
    "#     scheduler.step(val_loss)\n",
    "\n",
    "#     history[\"train_loss\"].append(train_loss)\n",
    "#     history[\"train_psnr\"].append(train_psnr)\n",
    "#     history[\"val_loss\"].append(val_loss)\n",
    "#     history[\"val_psnr\"].append(val_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_for_resolution_pairs(resol_1, resol_2, psnr_weight=PSNR_WEIGHT):\n",
    "    INPUT_DIR = f\"data/resolution_{resol_1}\"\n",
    "    TARGET_DIR = f\"data/resolution_{resol_2}\"\n",
    "\n",
    "    num_images = len([f for f in os.listdir(INPUT_DIR) if f.endswith(('.jpg', '.png', '.jpeg', '.webp'))])\n",
    "    train_indices, val_indices = get_split_indices(num_images, test_indices)\n",
    "\n",
    "    train_loader = DataLoader(LocalImageDataset(INPUT_DIR, TARGET_DIR, train_indices), batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(LocalImageDataset(INPUT_DIR, TARGET_DIR, val_indices), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(LocalImageDataset(INPUT_DIR, TARGET_DIR, test_indices), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    save_ckpt = 2\n",
    "    checkpoint_dir = f\"ckpt/resolution_{resol_1}_{resol_2}\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    n_samples = 5\n",
    "    samples_to_visualize = DataLoader(LocalImageDataset(INPUT_DIR, TARGET_DIR, test_indices), batch_size=n_samples, shuffle=False)\n",
    "\n",
    "    sample_dir = f\"samples_{resol_1}_{resol_2}\"\n",
    "\n",
    "\n",
    "    device = get_device()\n",
    "    model = ResNetSR(upscale_factor=2, num_res_blocks=2, num_channels=1, num_features=32)\n",
    "    model = model.to(device)\n",
    "    mae_loss = nn.L1Loss()\n",
    "    criterion = CombinedLoss(mae_loss, EDGE_WEIGHT, psnr_weight)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='max',  # Focus on maximizing PSNR\n",
    "        factor=.2,  # More aggressive reduction\n",
    "        patience=2,   # Reduce LR sooner\n",
    "        threshold=0.01,  # Smaller threshold for improvement\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        train_loss, train_psnr = train_model_single_epoch(model, train_loader, criterion, optimizer, device, scaler=None, grad_clip=GRAD_CLIP)\n",
    "        val_loss, val_psnr = validate_model_single_epoch(model, val_loader, criterion, device)\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"[Epoch {epoch}/{NUM_EPOCHS}]\",\n",
    "                f\"Train Loss: {train_loss:.4f}, PSNR: {train_psnr:.2f} | \"\n",
    "                f\"Val Loss: {val_loss:.4f}, PSNR: {val_psnr:.2f} | \"\n",
    "                f\"lr: {round(current_lr, 5)}\")\n",
    "\n",
    "        if epoch % save_ckpt == 0:\n",
    "            save_checkpoint(epoch+1, model, optimizer, history, checkpoint_dir)\n",
    "\n",
    "            save_samples(epoch+1, model, val_loader, device, sample_dir, samples_to_visualize)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_checkpoint(0, model, optimizer, history, checkpoint_dir)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_psnr\"].append(train_psnr)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_psnr\"].append(val_psnr)\n",
    "\n",
    "    sns.lineplot(\n",
    "        x=range(1, epoch + 1),\n",
    "        y=history[\"train_psnr\"],\n",
    "        label=\"Train PSNR\",\n",
    "        color=\"blue\"\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        x=range(1, epoch + 1),\n",
    "        y=history[\"val_psnr\"],\n",
    "        label=\"Validation PSNR\",\n",
    "        color=\"orange\"\n",
    "    )\n",
    "    plt.title(\"PSNR over epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"PSNR\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    os.mkdir(\"plots\", exist_ok=True)\n",
    "    plt.savefig(f\"plots/psnr_plot_{resol_1}_{resol_2}.png\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janysli/miniconda3/envs/text_super_resol/lib/python3.13/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 67/67 [00:07<00:00,  8.96it/s, loss=-3.8, psnr=13.5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/30] Train Loss: 34.1655, PSNR: 2.99 | Val Loss: -3.7655, PSNR: 13.42 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00,  9.64it/s, loss=-3.95, psnr=13.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/30] Train Loss: -3.8369, PSNR: 13.63 | Val Loss: -3.9131, PSNR: 13.86 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_3\n",
      "Saved 5 samples at epoch 3 to samples_64_128/epoch_3_samples.png\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  9.29it/s, loss=-4.01, psnr=14.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/30] Train Loss: -3.9270, PSNR: 13.88 | Val Loss: -3.9551, PSNR: 13.94 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00, 10.34it/s, loss=-3.94, psnr=13.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/30] Train Loss: -3.9698, PSNR: 13.99 | Val Loss: -3.9667, PSNR: 13.98 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_5\n",
      "Saved 5 samples at epoch 5 to samples_64_128/epoch_5_samples.png\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00,  9.63it/s, loss=-4.08, psnr=14.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/30] Train Loss: -4.0086, PSNR: 14.10 | Val Loss: -4.0250, PSNR: 14.14 | lr: 0.002\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  9.00it/s, loss=-4.02, psnr=14.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/30] Train Loss: -4.0245, PSNR: 14.14 | Val Loss: -4.0338, PSNR: 14.16 | lr: 0.002\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_7\n",
      "Saved 5 samples at epoch 7 to samples_64_128/epoch_7_samples.png\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  9.05it/s, loss=-4.06, psnr=14.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/30] Train Loss: -4.0357, PSNR: 14.17 | Val Loss: -4.0473, PSNR: 14.20 | lr: 0.002\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00, 10.34it/s, loss=-4.07, psnr=14.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/30] Train Loss: -4.0432, PSNR: 14.19 | Val Loss: -4.0495, PSNR: 14.21 | lr: 0.0004\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_9\n",
      "Saved 5 samples at epoch 9 to samples_64_128/epoch_9_samples.png\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00,  9.97it/s, loss=-4.09, psnr=14.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/30] Train Loss: -4.0462, PSNR: 14.20 | Val Loss: -4.0539, PSNR: 14.22 | lr: 0.0004\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  9.56it/s, loss=-4.09, psnr=14.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/30] Train Loss: -4.0479, PSNR: 14.20 | Val Loss: -4.0547, PSNR: 14.22 | lr: 0.0004\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_11\n",
      "Saved 5 samples at epoch 11 to samples_64_128/epoch_11_samples.png\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00,  9.66it/s, loss=-3.97, psnr=14]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/30] Train Loss: -4.0501, PSNR: 14.21 | Val Loss: -4.0553, PSNR: 14.22 | lr: 8e-05\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00, 10.33it/s, loss=-4.05, psnr=14.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/30] Train Loss: -4.0509, PSNR: 14.21 | Val Loss: -4.0563, PSNR: 14.23 | lr: 8e-05\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_13\n",
      "Saved 5 samples at epoch 13 to samples_64_128/epoch_13_samples.png\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  9.43it/s, loss=-3.98, psnr=14]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/30] Train Loss: -4.0512, PSNR: 14.21 | Val Loss: -4.0547, PSNR: 14.22 | lr: 8e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  8.49it/s, loss=-4.11, psnr=14.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/30] Train Loss: -4.0522, PSNR: 14.21 | Val Loss: -4.0560, PSNR: 14.22 | lr: 2e-05\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_15\n",
      "Saved 5 samples at epoch 15 to samples_64_128/epoch_15_samples.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00, 10.35it/s, loss=-4.09, psnr=14.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/30] Train Loss: -4.0520, PSNR: 14.21 | Val Loss: -4.0557, PSNR: 14.22 | lr: 2e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00,  9.85it/s, loss=-4.1, psnr=14.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/30] Train Loss: -4.0520, PSNR: 14.21 | Val Loss: -4.0572, PSNR: 14.23 | lr: 2e-05\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_17\n",
      "Saved 5 samples at epoch 17 to samples_64_128/epoch_17_samples.png\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00, 10.12it/s, loss=-4.05, psnr=14.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/30] Train Loss: -4.0525, PSNR: 14.22 | Val Loss: -4.0566, PSNR: 14.23 | lr: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00, 10.20it/s, loss=-4.05, psnr=14.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/30] Train Loss: -4.0524, PSNR: 14.21 | Val Loss: -4.0564, PSNR: 14.23 | lr: 0.0\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_19\n",
      "Saved 5 samples at epoch 19 to samples_64_128/epoch_19_samples.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00, 10.41it/s, loss=-4.12, psnr=14.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/30] Train Loss: -4.0530, PSNR: 14.22 | Val Loss: -4.0564, PSNR: 14.23 | lr: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00, 10.41it/s, loss=-4.01, psnr=14.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/30] Train Loss: -4.0524, PSNR: 14.21 | Val Loss: -4.0565, PSNR: 14.23 | lr: 0.0\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_21\n",
      "Saved 5 samples at epoch 21 to samples_64_128/epoch_21_samples.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:06<00:00, 10.24it/s, loss=-3.99, psnr=14]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/30] Train Loss: -4.0522, PSNR: 14.21 | Val Loss: -4.0566, PSNR: 14.23 | lr: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  9.54it/s, loss=-4.06, psnr=14.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/30] Train Loss: -4.0526, PSNR: 14.22 | Val Loss: -4.0566, PSNR: 14.23 | lr: 0.0\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_23\n",
      "Saved 5 samples at epoch 23 to samples_64_128/epoch_23_samples.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  9.12it/s, loss=-4.06, psnr=14.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/30] Train Loss: -4.0522, PSNR: 14.21 | Val Loss: -4.0566, PSNR: 14.23 | lr: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  8.45it/s, loss=-4.03, psnr=14.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/30] Train Loss: -4.0522, PSNR: 14.21 | Val Loss: -4.0566, PSNR: 14.23 | lr: 0.0\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_25\n",
      "Saved 5 samples at epoch 25 to samples_64_128/epoch_25_samples.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:08<00:00,  8.13it/s, loss=-4.04, psnr=14.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/30] Train Loss: -4.0524, PSNR: 14.21 | Val Loss: -4.0566, PSNR: 14.23 | lr: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:08<00:00,  8.35it/s, loss=-4.04, psnr=14.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/30] Train Loss: -4.0523, PSNR: 14.21 | Val Loss: -4.0566, PSNR: 14.23 | lr: 0.0\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_27\n",
      "Saved 5 samples at epoch 27 to samples_64_128/epoch_27_samples.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  8.59it/s, loss=-4.03, psnr=14.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/30] Train Loss: -4.0525, PSNR: 14.22 | Val Loss: -4.0566, PSNR: 14.23 | lr: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  8.45it/s, loss=-4.09, psnr=14.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/30] Train Loss: -4.0526, PSNR: 14.22 | Val Loss: -4.0566, PSNR: 14.23 | lr: 0.0\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_29\n",
      "Saved 5 samples at epoch 29 to samples_64_128/epoch_29_samples.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  8.62it/s, loss=-3.94, psnr=13.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/30] Train Loss: -4.0523, PSNR: 14.21 | Val Loss: -4.0566, PSNR: 14.23 | lr: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:07<00:00,  8.76it/s, loss=-4.1, psnr=14.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/30] Train Loss: -4.0524, PSNR: 14.21 | Val Loss: -4.0566, PSNR: 14.23 | lr: 0.0\n",
      "Model checkpoint saved at ckpt/resolution_64_128/ckpt_31\n",
      "Saved 5 samples at epoch 31 to samples_64_128/epoch_31_samples.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plots/psnr_plot_64_128.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model_for_resolution_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 81\u001b[0m, in \u001b[0;36mtrain_model_for_resolution_pairs\u001b[0;34m(resol_1, resol_2)\u001b[0m\n\u001b[1;32m     79\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m     80\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 81\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplots/psnr_plot_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresol_1\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresol_2\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/miniconda3/envs/text_super_resol/lib/python3.13/site-packages/matplotlib/pyplot.py:1243\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1240\u001b[0m fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[0;32m-> 1243\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/text_super_resol/lib/python3.13/site-packages/matplotlib/figure.py:3490\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3488\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3489\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[0;32m-> 3490\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/text_super_resol/lib/python3.13/site-packages/matplotlib/backend_bases.py:2184\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2182\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2183\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2184\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2185\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2186\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2187\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2188\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2190\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/miniconda3/envs/text_super_resol/lib/python3.13/site-packages/matplotlib/backend_bases.py:2040\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2036\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2039\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2040\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2041\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2042\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2043\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m~/miniconda3/envs/text_super_resol/lib/python3.13/site-packages/matplotlib/backends/backend_agg.py:481\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 481\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/text_super_resol/lib/python3.13/site-packages/matplotlib/backends/backend_agg.py:430\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    429\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 430\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/text_super_resol/lib/python3.13/site-packages/matplotlib/image.py:1634\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1632\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1633\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1634\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/text_super_resol/lib/python3.13/site-packages/PIL/Image.py:2591\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2589\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2591\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2593\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plots/psnr_plot_64_128.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model_for_resolution_pairs(64, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:34<00:00,  1.95it/s, loss=0.226, psnr=15.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/30] Train Loss: 9.4055, PSNR: 6.08 | Val Loss: 0.2283, PSNR: 15.72 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.41it/s, loss=0.193, psnr=16.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/30] Train Loss: 0.2054, PSNR: 16.15 | Val Loss: 0.1873, PSNR: 16.52 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/ckpt_3\n",
      "Saved 5 samples at epoch 3 to samples_128_256/epoch_3_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s, loss=0.152, psnr=17.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/30] Train Loss: 0.1650, PSNR: 16.85 | Val Loss: 0.1488, PSNR: 17.28 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:28<00:00,  2.38it/s, loss=0.143, psnr=17.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/30] Train Loss: 0.1439, PSNR: 17.42 | Val Loss: 0.1384, PSNR: 17.68 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/ckpt_5\n",
      "Saved 5 samples at epoch 5 to samples_128_256/epoch_5_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.43it/s, loss=0.127, psnr=17.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/30] Train Loss: 0.1312, PSNR: 17.86 | Val Loss: 0.1262, PSNR: 18.07 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.45it/s, loss=0.113, psnr=18.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/30] Train Loss: 0.1179, PSNR: 18.34 | Val Loss: 0.1135, PSNR: 18.51 | lr: 0.005\n",
      "Model checkpoint saved at ckpt/ckpt_7\n",
      "Saved 5 samples at epoch 7 to samples_128_256/epoch_7_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:28<00:00,  2.34it/s, loss=0.103, psnr=19]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/30] Train Loss: 0.1111, PSNR: 18.63 | Val Loss: 0.1107, PSNR: 18.70 | lr: 0.005\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.41it/s, loss=0.106, psnr=18.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/30] Train Loss: 0.1065, PSNR: 18.85 | Val Loss: 0.1045, PSNR: 18.95 | lr: 0.005\n",
      "Model checkpoint saved at ckpt/ckpt_9\n",
      "Saved 5 samples at epoch 9 to samples_128_256/epoch_9_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.40it/s, loss=0.11, psnr=18.9]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/30] Train Loss: 0.1016, PSNR: 19.10 | Val Loss: 0.1116, PSNR: 18.80 | lr: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.43it/s, loss=0.0945, psnr=19.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/30] Train Loss: 0.0977, PSNR: 19.29 | Val Loss: 0.0948, PSNR: 19.41 | lr: 0.0025\n",
      "Model checkpoint saved at ckpt/ckpt_11\n",
      "Saved 5 samples at epoch 11 to samples_128_256/epoch_11_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.40it/s, loss=0.0887, psnr=19.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/30] Train Loss: 0.0937, PSNR: 19.48 | Val Loss: 0.0924, PSNR: 19.55 | lr: 0.0025\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.45it/s, loss=0.0841, psnr=20]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/30] Train Loss: 0.0915, PSNR: 19.61 | Val Loss: 0.0904, PSNR: 19.64 | lr: 0.0025\n",
      "Model checkpoint saved at ckpt/ckpt_13\n",
      "Saved 5 samples at epoch 13 to samples_128_256/epoch_13_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.43it/s, loss=0.0866, psnr=19.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/30] Train Loss: 0.0894, PSNR: 19.72 | Val Loss: 0.0879, PSNR: 19.80 | lr: 0.0025\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.45it/s, loss=0.094, psnr=19.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/30] Train Loss: 0.0870, PSNR: 19.85 | Val Loss: 0.0862, PSNR: 19.89 | lr: 0.00125\n",
      "Model checkpoint saved at ckpt/ckpt_15\n",
      "Saved 5 samples at epoch 15 to samples_128_256/epoch_15_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.43it/s, loss=0.0853, psnr=20]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/30] Train Loss: 0.0858, PSNR: 19.92 | Val Loss: 0.0854, PSNR: 19.94 | lr: 0.00125\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.46it/s, loss=0.0902, psnr=19.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/30] Train Loss: 0.0847, PSNR: 19.98 | Val Loss: 0.0839, PSNR: 20.03 | lr: 0.00125\n",
      "Model checkpoint saved at ckpt/ckpt_17\n",
      "Saved 5 samples at epoch 17 to samples_128_256/epoch_17_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:28<00:00,  2.35it/s, loss=0.0884, psnr=19.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/30] Train Loss: 0.0835, PSNR: 20.05 | Val Loss: 0.0829, PSNR: 20.09 | lr: 0.00125\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.43it/s, loss=0.076, psnr=20.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/30] Train Loss: 0.0824, PSNR: 20.12 | Val Loss: 0.0821, PSNR: 20.14 | lr: 0.00063\n",
      "Model checkpoint saved at ckpt/ckpt_19\n",
      "Saved 5 samples at epoch 19 to samples_128_256/epoch_19_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.43it/s, loss=0.0755, psnr=20.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/30] Train Loss: 0.0819, PSNR: 20.15 | Val Loss: 0.0814, PSNR: 20.17 | lr: 0.00063\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.44it/s, loss=0.0797, psnr=20.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/30] Train Loss: 0.0814, PSNR: 20.18 | Val Loss: 0.0809, PSNR: 20.20 | lr: 0.00063\n",
      "Model checkpoint saved at ckpt/ckpt_21\n",
      "Saved 5 samples at epoch 21 to samples_128_256/epoch_21_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.41it/s, loss=0.0764, psnr=20.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/30] Train Loss: 0.0807, PSNR: 20.22 | Val Loss: 0.0805, PSNR: 20.23 | lr: 0.00063\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s, loss=0.0764, psnr=20.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/30] Train Loss: 0.0802, PSNR: 20.25 | Val Loss: 0.0800, PSNR: 20.26 | lr: 0.00031\n",
      "Model checkpoint saved at ckpt/ckpt_23\n",
      "Saved 5 samples at epoch 23 to samples_128_256/epoch_23_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.40it/s, loss=0.0804, psnr=20.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/30] Train Loss: 0.0799, PSNR: 20.27 | Val Loss: 0.0797, PSNR: 20.28 | lr: 0.00031\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s, loss=0.0795, psnr=20.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/30] Train Loss: 0.0795, PSNR: 20.29 | Val Loss: 0.0793, PSNR: 20.30 | lr: 0.00031\n",
      "Model checkpoint saved at ckpt/ckpt_25\n",
      "Saved 5 samples at epoch 25 to samples_128_256/epoch_25_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:28<00:00,  2.39it/s, loss=0.0783, psnr=20.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/30] Train Loss: 0.0793, PSNR: 20.31 | Val Loss: 0.0792, PSNR: 20.32 | lr: 0.00031\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:58<00:00,  1.15it/s, loss=0.0834, psnr=20.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/30] Train Loss: 0.0790, PSNR: 20.33 | Val Loss: 0.0788, PSNR: 20.33 | lr: 0.00016\n",
      "Model checkpoint saved at ckpt/ckpt_27\n",
      "Saved 5 samples at epoch 27 to samples_128_256/epoch_27_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:30<00:00,  2.21it/s, loss=0.0776, psnr=20.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/30] Train Loss: 0.0788, PSNR: 20.34 | Val Loss: 0.0787, PSNR: 20.34 | lr: 0.00016\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [05:27<00:00,  4.88s/it, loss=0.0819, psnr=20.2]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/30] Train Loss: 0.0786, PSNR: 20.35 | Val Loss: 0.0785, PSNR: 20.35 | lr: 0.00016\n",
      "Model checkpoint saved at ckpt/ckpt_29\n",
      "Saved 5 samples at epoch 29 to samples_128_256/epoch_29_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:55<00:00,  1.21it/s, loss=0.0782, psnr=20.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/30] Train Loss: 0.0785, PSNR: 20.36 | Val Loss: 0.0784, PSNR: 20.35 | lr: 0.00016\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s, loss=0.0795, psnr=20.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/30] Train Loss: 0.0783, PSNR: 20.37 | Val Loss: 0.0782, PSNR: 20.37 | lr: 8e-05\n",
      "Model checkpoint saved at ckpt/ckpt_31\n",
      "Saved 5 samples at epoch 31 to samples_128_256/epoch_31_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    }
   ],
   "source": [
    "train_model_for_resolution_pairs(128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [2:36:16<00:00, 139.94s/it, loss=0.135, psnr=19.4]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/30] Train Loss: 19.0649, PSNR: -2.96 | Val Loss: 0.1273, PSNR: 20.24 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [41:02<00:00, 36.76s/it, loss=0.16, psnr=16.9]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/30] Train Loss: 0.2267, PSNR: 17.36 | Val Loss: 0.3321, PSNR: 10.29 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/ckpt_3\n",
      "Saved 5 samples at epoch 3 to samples_256_512/epoch_3_samples.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [1:00:27<00:00, 54.15s/it, loss=0.1, psnr=21.7]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/30] Train Loss: 0.1504, PSNR: 19.41 | Val Loss: 0.1403, PSNR: 19.20 | lr: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [1:33:15<00:00, 83.52s/it, loss=0.112, psnr=20.8]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/30] Train Loss: 0.2149, PSNR: 16.72 | Val Loss: 0.1202, PSNR: 20.77 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/ckpt_5\n",
      "Saved 5 samples at epoch 5 to samples_256_512/epoch_5_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [57:10<00:00, 51.21s/it, loss=0.139, psnr=19.6]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/30] Train Loss: 1.0411, PSNR: 11.72 | Val Loss: 0.1432, PSNR: 19.02 | lr: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [1:18:47<00:00, 70.57s/it, loss=0.0949, psnr=21.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/30] Train Loss: 0.3516, PSNR: 18.81 | Val Loss: 0.0965, PSNR: 21.19 | lr: 0.01\n",
      "Model checkpoint saved at ckpt/ckpt_7\n",
      "Saved 5 samples at epoch 7 to samples_256_512/epoch_7_samples.png\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [40:51<00:00, 36.58s/it, loss=0.0752, psnr=22]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/30] Train Loss: 0.0806, PSNR: 22.01 | Val Loss: 0.0748, PSNR: 22.15 | lr: 0.005\n",
      "Model checkpoint saved at ckpt/ckpt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 67/67 [1:46:44<00:00, 95.60s/it, loss=0.0529, psnr=23.4]   \n"
     ]
    }
   ],
   "source": [
    "train_model_for_resolution_pairs(256, 512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_super_resol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
